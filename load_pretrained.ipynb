{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_pretrained.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuJwei/Learning-CoLab/blob/master/load_pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeqsTtUrZE7Q",
        "colab_type": "text"
      },
      "source": [
        "This notebook shows how to test the HD3 pretrained model in Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGsVg0apZeIm",
        "colab_type": "text"
      },
      "source": [
        "Download the file from the [GitHub](https://github.com/ucbdrive/hd3) and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H6iwxFOaN0B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30032249-b483-4997-8dbf-faa914757004"
      },
      "source": [
        "# current workplace\n",
        "!pwd\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/hd3-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvZR71t1Y61K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip hd3-master.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDaf4mLtaRMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change work directory\n",
        "import os\n",
        "os.chdir('./hd3-master')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkqSuipGak97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import hd3model as models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "corr_range = [4, 4, 4, 4, 4, 4]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwqtWzB4Z5j0",
        "colab_type": "text"
      },
      "source": [
        "I tried to write the code below to test it, but it doesn't work so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3iAPb3ug-jS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.HD3Model('stereo', 'dlaup', 'hda', corr_range).cuda()\n",
        "\n",
        "import logging\n",
        "# logger\n",
        "def get_logger():\n",
        "    logger_name = \"main-logger\"\n",
        "    logger = logging.getLogger(logger_name)\n",
        "    logger.setLevel(logging.INFO)\n",
        "    handler = logging.StreamHandler()\n",
        "    fmt = \"[%(asctime)s %(levelname)s %(filename)s line %(lineno)d %(process)d] %(message)s\"\n",
        "    handler.setFormatter(logging.Formatter(fmt))\n",
        "    logger.addHandler(handler)\n",
        "    return logger\n",
        "  \n",
        "logger = get_logger()  \n",
        "# logger.info(model)\n",
        "\n",
        "\n",
        "model = nn.DataParallel(model).cuda()\n",
        "cudnn.enabled = True\n",
        "cudnn.benchmark = True\n",
        "\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "def load_pretrained_model(filepath):\n",
        "    # this model was trained on gpu\n",
        "    pretrained = torch.load(filepath)\n",
        "#     set_trace()\n",
        "    #model = pretrained['model']\n",
        "    model.load_state_dict(pretrained['state_dict'], strict= True)\n",
        "    for parameter in model.parameters():\n",
        "        parameter.requires_grad = False\n",
        "\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Don't know why i cannot load the model successfully.    \n",
        "model = load_pretrained_model('hd3sc_things_kitti-368975c0.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4eChJy60sSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTZ4FvKcnjtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEiQwOHmaPBu",
        "colab_type": "text"
      },
      "source": [
        "Install cupy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s0L2KswatbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "9497e72c-b0b0-4b75-9eb9-88fd64787749"
      },
      "source": [
        "!pip install cupy-cuda100"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cupy-cuda100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/2e/189676f6b19572f1e4b1ab3ca31e789c2d7ce1dc707be2ad2fed4e6fb3ea/cupy_cuda100-6.1.0-cp36-cp36m-manylinux1_x86_64.whl (354.4MB)\n",
            "\u001b[K     |████████████████████████████████| 354.4MB 64kB/s \n",
            "\u001b[?25hRequirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100) (0.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100) (1.16.4)\n",
            "Installing collected packages: cupy-cuda100\n",
            "Successfully installed cupy-cuda100-6.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T7-K23IaWNq",
        "colab_type": "text"
      },
      "source": [
        "Download pretrained model from the website."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KJUCjzFh0gI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget dl.yf.io/hd3/models/hd3f_chairs-04bf114d.pth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tir1xKKlsKIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download file to a specific address\n",
        "!wget dl.yf.io/hd3/models/hd3sc_things_kitti-368975c0.pth -O ../hd3-master/000.pth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRk3JI4A192m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --help"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3VqPsXaagbO",
        "colab_type": "text"
      },
      "source": [
        "Try to run the inference.py directly. It works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNZavmioN9px",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fae9df3-086a-4ad3-a994-0836e055dfe1"
      },
      "source": [
        "# Write a data list of a image pair to read\n",
        "# Creat a folder test_data in the current working dictionary to put image pairs\n",
        "%%writefile lists/my_list.txt\n",
        "test_data/image_2/000000_10.png test_data/image_3/000000_10.png"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting lists/my_list.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPffF5gZLlnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!python -u inference.py \\\n",
        "  --task=stereo \\\n",
        "  --data_root= \\\n",
        "  --data_list='lists/my_list.txt'\\\n",
        "  --context \\\n",
        "  --encoder=dlaup \\\n",
        "  --decoder=hda \\\n",
        "  --batch_size=1 \\\n",
        "  --workers=16 \\\n",
        "  --flow_format=png \\\n",
        "  \\\n",
        "  --model_path='hd3sc_things_kitti-368975c0.pth' \\\n",
        "  --save_folder=path_to_save_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}